# AI is......

 On the very broad topic of AI is..... there are many places to take this prompt
 
 AI is a tool, and whether the impact is good or bad depends on the wielder. <br>
 AI does exactly what you tell it to do but maybe not what you intend it to do. <br>
 AI is made tremedous advances but is still far from what the general public would consider as effective. <br>
 
 Work on AI spans back as far as human imagination, or at least it feels that way.  It certainly was happening prior to the 21st century.  Calculators were an "AI".  However, as the methods became easier to understand, they were labelled as "algorithms" rather thatn the mythic AI.  AI takes in inputs which humans label and optimizes on an ouput based on what humans determine to be valid.  Rather than being a source of mysticism, it reveals biases of humans in the inputs and labeling of those inputs they provide. It has no determination of good or bad, just the optimization of the rules the programming human deems as valid.  
 
 AI will accelerate human work by massively accelerating testing and simulations.  However, this speed of action will outpace the writting of policies on how the technology can be used fairly and ethically.  I believe the greatest threat of AI is that it will unleash a wild west that does not consider the greater society good.  The idea that AI will take over the world and erradicate all humans seems flawed.  First, AI can analyze data and make a recommendation but it needs a machine or automation system to carry out the recommendation.  These two can be separated to allow for some human governance.  Second, AI does not have any feelings about its answers.  It does not feel something should be right or wrong, good or bad for society since it has no concept of society.  It just knows it reached the min or max of a dataset.  AI becoming sentient does not make sense based on the fields of today's technology.  Could this change tomorrow? Sure, yes but without the existence of the technology it is mute to debate.  
 
 AI is capable of doing very specific tasks that a two year old is good at but just faster and at a larger scale.  However, it cannot use judgement or formulate a theory -  well, depending on how you define judgement and theory.  Ha ha, the devil is in the details.  AI can judge for similiarity like two pictures being 85% similar.  It can judge for min/max like the most efficient / least waste of something.  But this is a narrow piece of the human concept of judgement.  AI can create a theory in terms of an equation to model a task.  It can even run back propogation to derive the inputs from the outputs.  However, this is also a narrow slice of the human concept of theory.  A part of this may be due to these concept being subjective and have an evovling definition.  Leave it to the humans to change the rules of the game.
 
 "Geniusmakers" talks about Silicon Valley's quest for general AI.  It is a daunting task, something that a 5 year old would have but we would not know how to program.  It would be able to take in "unlabeled inputs" and derive characteristic of it "unsupervised".  In terms of the tremendous advances in AI, lingustic semantic understanding is a major breakthrough to understand complex language patterns.   I am truly impressed.  However, I believe it currently only works relegated to very narrow topic domains.  But why shouldn't that be so?  If a human were to learn another language today, they would battle with a lot of the sematics and grammar rules and idioms of that language and culture.  It's not just words but also context!  Machine translations are sometimes plagued with having certain portions of unsensible translations, but wouldn't a novice human have that same issue?  Is the problem more that we are overly critical on machines or we don't know how to do this ourselves so how can we tell the machine to do it?  There is also the expectation that the machines will invent new things.  Some examples today in creating picture and music or interesting but I would not say its invention but rather the detection of a pattern that humans have not thought of or were mentally blocked from trying.  It is not the creativity in coming up with a new genre of music.  But isn't the problem also with our expectations?  No human came up with a new composition wihtout first learning the existing samples in that field.  
 
 Also, I would be curious if researchers have looked at cross training.  To use a machine trained in one adjacent field and try to be creative in a new field.  I think what the AI needs are a set of different mental models.  However, having a general AI that has all these mental models does not seem to make sense as it would be complicated.  
 
 AI is exactly what we mean it to be.  I think that humans just need to be clearer in writting down the problem we want to solve.  
